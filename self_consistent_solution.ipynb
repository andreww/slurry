{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a147ba8",
   "metadata": {},
   "source": [
    "# Multiple particles falling in the F-layer\n",
    "\n",
    "This notebook outlines how we can use our model of a single falling and growing iron particle \n",
    "to create a self consistent solution to properties of the F-layer and an estimate of the inner\n",
    "core growth rate. We assume at the outset that we can track the growth and position of a single\n",
    "falling iron particle with time. This is set up as a pair of coupled ODEs and solved as an IVP. \n",
    "This is implemented inside the `boundary_layer` model making use of the SciPy `integrate.solve_ivp`\n",
    "interface to an explicit 5th order Runga-Kutta solver. We make extensive use of event tracking and\n",
    "interpolated solutions given by this implementation.\n",
    "\n",
    "The aim is to (1) look at how the results of our method varies with input parameters and (2)\n",
    "compare our non-equilibrium approach to a simple equilibrium model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db92f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.optimize as spo\n",
    "import scipy.interpolate as spi\n",
    "import boundary_layer\n",
    "import feo_thermodynamics as feot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305ae808",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyshtools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-674c808508f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/Peter Davies/Documents/Github/lema/lema/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mearth_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mearth_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lema\\lema\\earth_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlayered_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspherical_shell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lema\\lema\\layered_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyshtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mshtools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \"\"\"\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyshtools'"
     ]
    }
   ],
   "source": [
    "# We will use PREM for pressure, gravity etc.\n",
    "import sys\n",
    "sys.path.append('/Users/Peter Davies/Documents/Github/lema/lema/')\n",
    "import earth_model\n",
    "prem = earth_model.Prem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38227903",
   "metadata": {},
   "source": [
    "## F-layer setup\n",
    "\n",
    "We need a reasonable description of the F-layer. We do this by defining a radius for the ICB \n",
    "and a radius for the top of the F-layer, assume that pressure (and gravity) are given by PREM,\n",
    "and define functions for temperature and composition. (The following function generates the functions\n",
    "we'll need). \n",
    "\n",
    "The (total) composition is assumed to be constant in the core above the F-layer, and may vary as a linear \n",
    "function of radius within the F-layer. This is set up by providing two compositions, one\n",
    "at the top and one at the bottom of the F-layer. These are provided as mole fraction Fe\n",
    "and are needed to set up the temperature.\n",
    "\n",
    "For temperature we extrapolate down an adiabat until we reach the top of the F-layer and then\n",
    "assume a linear variation in temperature with radius. The adiabatic temperature is given by:\n",
    "\n",
    "$$ T_a(r) = T_{CMB} \\left(\\frac{\\rho(r)}{\\rho_{CMB}}\\right)^{\\gamma} $$\n",
    "\n",
    "where $\\gamma$ is the Grunissen parameter for the core (e.g. 1.5) and $T_{CMB}$ is the \n",
    "temperature at the CMB. We fix $\\gamma$, assume PREM for the density, and find $T_{CMB}$ such\n",
    "that $T_a(r)$ is equal to the liquidus (at our chosen composition) at the top of the F-layer.\n",
    "This is done by root finding. \n",
    "We choose the temperature at the ICB by further extrapolating down the adiabat and applying \n",
    "a small change (or order 10 K) such that the F-layer can be sub- (or super-) adiabatic.\n",
    "\n",
    "Note that allowing the temperature and composition to vary with radius could allow the\n",
    "F-layer to depart from the two phase region (either by dipping below the solidus/eutectic\n",
    "temperature or by exceeding the pressure-dependent liquidus). Do check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_flayer_functions(r_icb, r_cmb, r_flayer_top, gamma, delta_t_icb, xfe_adiabatic, xfe_icb):\n",
    "    \"\"\"\n",
    "    This defines the radial functions we are going to need to model the f-layer\n",
    "    \n",
    "    Our input parameters are the (total) oxygen content at the top and bottom of \n",
    "    the layer, the subadiabatic cooling through the layer, a value for gamma\n",
    "    for the adiabatic core and a thickness of the layer. We first use this \n",
    "    to find the liquidus temperature at the top of the F-layer. We then require\n",
    "    the CMB temperature to generate an adiabat that intersects the liquidus at the\n",
    "    top of the f-layer.\n",
    "    \n",
    "    Arguments are:\n",
    "    \n",
    "    r_icb: ICB radius in m\n",
    "    r_cmb: core mantle boundary radius in m\n",
    "    r_flayer_top: radius of the top of the f-layer in m\n",
    "    gamma: gruneisen parameter for adiabatic core, dimensionless (1.5 is a typical value)\n",
    "    delta_t_icb: subadiabatic temperature depression at the ICB in K, 10 K is a sensible value\n",
    "    xfe_adiabatic: oxygen content (as mol frac Fe) of the adiabatic core (and top of the F-layer)\n",
    "                    8-17 mol % O (i.e. 0.92-0.83) are sensible values\n",
    "    xfe_icb: oxygen content (as mol frac Fe) at the bottom of the F-layer. NB: this is the total oxygen \n",
    "             content. As O partititons into the liquid the liquid will be enriched. \n",
    "    \n",
    "    We end up returning a functions that can give the total oxygen content as a function\n",
    "    of radius, the temperature as a function of radius, and the pressure (from PREM) as\n",
    "    a function of radius. In the F-layer we assume linear temperature and composition\n",
    "    profiles. These functions are (numpy) vectorized and take the radii in m. \n",
    "    \"\"\"\n",
    "    # First find the liquidus temperature at the top of the F-layer... we know P (from PREM)\n",
    "    # and X (from our input). NB: my PREM module works in km and does not like vector input.\n",
    "    # This is quite slow and could be optimised by avoiding the double brentq calls!\n",
    "    tl_top_flayer = feot.find_liquidus(xfe_adiabatic, prem.pressure(radius_top_flayer/1000.0))\n",
    "    print(\"Liquidus temperature at top of F-layer is\", tl_top_flayer, \"K\")\n",
    "    \n",
    "    # Now we need to work out the adiabatic temperature profile that intersects the liquidus \n",
    "    # at the top of the F-layer. \n",
    "    rho_cmb = prem.density((radius_cmb-0.1)/1000.0) # -0.1 for core, not mantle rho\n",
    "    rho_top_flayer = prem.density(radius_top_flayer/1000.0)\n",
    "    def _t_error_top_flayer(tcmb):\n",
    "        \"\"\"\n",
    "        For a given CMB temperature, calculate the difference between the temperature\n",
    "        at the top of the f-layer and the liquidus temperature. We'll need to set \n",
    "        tcmb such that this is zero!\n",
    "        \"\"\"\n",
    "        adabat_t_top_flayer = tcmb * (rho_top_flayer/rho_cmb)**gamma\n",
    "        t_error = adabat_t_top_flayer - tl_top_flayer\n",
    "        return t_error\n",
    "    t_cmb = spo.brentq(_t_error_top_flayer, 1000, 8000)\n",
    "    \n",
    "    print(\"Temperature CMB is\", t_cmb, \"K\")\n",
    "    \n",
    "    # We can now build our function to give the adiabatic temperature\n",
    "    rho_icb = prem.density(radius_inner_core/1000.0)\n",
    "    adabat_t_top_flayer = t_cmb * (rho_top_flayer/rho_cmb)**gamma\n",
    "    adabat_icb = t_cmb * (rho_icb/rho_cmb)**gamma\n",
    "    @np.vectorize\n",
    "    def adiabatic_temperature_function(r):\n",
    "        temp = t_cmb * (prem.density(r/1000.0)/rho_cmb)**gamma\n",
    "        return temp\n",
    "    \n",
    "    # And the function to give the 'real' temperature (including a subadiabatic layer)\n",
    "    # We'll base temperature on an adiabat (temperature at top of F-layer)\n",
    "    # and then assume it's linear to a subadiabatic ICB temperature\n",
    "    # Do note that we cannot use the ICB as a tie point as (1) the F-layer\n",
    "    # is not adiabatic and (2) we are not assuming phase equilibrium at the ICB\n",
    "    # which means the ICB need not be at any particular melting temperature. \n",
    "    # This is an important point (probably the most important point if we introduce\n",
    "    # non-equilibrium processes).\n",
    "    temperature_icb = adabat_icb - delta_t_icb\n",
    "    @np.vectorize\n",
    "    def temperature_function(r):\n",
    "        if r > radius_top_flayer:\n",
    "            temp = t_cmb * (prem.density(r/1000.0)/rho_cmb)**gamma\n",
    "        else: # Will give value inside inner core, but we may need that for IVP solver...\n",
    "            temp = temperature_icb + (r - r_icb)*(\n",
    "                (adabat_t_top_flayer-temperature_icb)/(r_flayer_top-r_icb))\n",
    "        return temp\n",
    "    \n",
    "\n",
    "    # Finally, a function to give the composition everywhere\n",
    "    @np.vectorize\n",
    "    def composition_function(r):\n",
    "        if r > radius_top_flayer:\n",
    "            xfe = xfe_adiabatic\n",
    "        else:\n",
    "            xfe = xfe_icb + (r - r_icb)*(\n",
    "                (xfe_adiabatic-xfe_icb)/(r_flayer_top-r_icb))\n",
    "        return xfe\n",
    "    \n",
    "    @np.vectorize           \n",
    "    def pressure_function(r):\n",
    "        return prem.pressure(r/1000.0)\n",
    "    \n",
    "    @np.vectorize\n",
    "    def gravity_function(r):\n",
    "        return prem.gravity(r/1000.0)\n",
    "    \n",
    "    return temperature_function, adiabatic_temperature_function, composition_function, \\\n",
    "        pressure_function, gravity_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we set all the F-layer parameters. Quite slow (due to liquidus calc I think)\n",
    "\n",
    "# F-layer setup\n",
    "radius_inner_core = 1221.5e3\n",
    "radius_top_flayer = radius_inner_core + 200.0e3 # 200 km thick.\n",
    "radius_cmb = 3480.0e3 # We only need this for setup.\n",
    "gamma = 1.5\n",
    "\n",
    "# Check PREM works\n",
    "print(\"Pressure at ICB:\", prem.pressure(radius_inner_core/1000.0), \"GPa\")\n",
    "print(\"Pressure at top of F-layer\", prem.pressure(radius_top_flayer/1000.0), \"GPa\")\n",
    "print(\"g at ICB:\", prem.gravity(radius_inner_core/1000.0), \"m/s**2\")\n",
    "print(\"g at top of F-layer\", prem.gravity(radius_top_flayer/1000.0), \"m/s**2\")\n",
    "\n",
    "# Generate the functions for temperautre,\n",
    "# composition, pressure and gravity\n",
    "tfunc, atfunc, xfunc, pfunc, \\\n",
    "    gfunc = setup_flayer_functions(radius_inner_core, radius_cmb, radius_top_flayer, \n",
    "                                                    gamma, 10.0, 0.92, 0.92)\n",
    "\n",
    "# Interpolate onto radius for plotting\n",
    "rs = np.linspace(radius_inner_core, radius_inner_core+500.0E3)\n",
    "ts = tfunc(rs)\n",
    "ats = atfunc(rs)\n",
    "ps = pfunc(rs)\n",
    "xs = xfunc(rs)\n",
    "# Find the P-X dependent liquidus (storing the temperature at each point)\n",
    "tl = feot.find_liquidus(xs, ps)\n",
    "\n",
    "\n",
    "# Plot the F-layer setup alongside the liquidus\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Radius (km)')\n",
    "ax1.set_ylabel('Temperature (K)', color=color)\n",
    "ax1.plot(rs/1000.0, ts, color=color)\n",
    "ax1.plot(rs/1000.0, ats, color=color, ls='--')\n",
    "ax1.plot(rs/1000.0, tl, color='k', ls=':')\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "#ax1.set_ylim([5900, 6200])\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Pressure (GPs)', color=color)  \n",
    "ax2.plot(rs/1000.0, ps, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim([280, 330])\n",
    "\n",
    "fig.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc8df3",
   "metadata": {},
   "source": [
    "## Equilibrium calculation\n",
    "\n",
    "We've covered all of this before elsewhere. The only innovation is to \n",
    "allow pressure and composition to vary with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a78dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "equilib_vol_frac = feot.volume_fraction_solid(xs, ps, ts)\n",
    "x_lq, phi_fe, phi_lq, phi_feo, phi_solid = feot.phase_relations_molar(xs, ps, ts)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2)\n",
    "ax[0].plot(rs/1000.0, equilib_vol_frac)\n",
    "ax[0].set_ylabel('Volume fraction solid')\n",
    "ax[0].set_xlabel('Radius (km)')\n",
    "ax[1].plot(rs/1000.0, x_lq)\n",
    "ax[1].set_ylabel('Liquid composition \\n(in two phase mixture)')\n",
    "ax[1].set_xlabel('Radius (km)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb14bb8",
   "metadata": {},
   "source": [
    "**To Do:** \n",
    "1. work out why we have the steps in the melting curve and the phase relations output. Looks like\n",
    "some numerical convergence thing but I would expect that to be more random.\n",
    "2. Think about falling time and crystal size in the equilibrium case. \n",
    "3. Think about physical propertiese (layer density structure, bulk modulii, P-wave velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c9fa3",
   "metadata": {},
   "source": [
    "## Non-equilibrium calculation\n",
    "\n",
    "For the overall non-equilibrium calculation we make use of the previously implemented\n",
    "code to track the growth and falling velocity of an isolated crystal. The innovation\n",
    "is in bringing these together into a model of the F-layer. Setup of the F-layer is\n",
    "described above.\n",
    "\n",
    "### The particle density and optimisation of the interaction volume\n",
    "\n",
    "Thus far we have treated the 'interaction volume' around the falling particles as an\n",
    "externally imposed parameter. However, we would like the composition (in terms of \n",
    "oxygen content) of the F-layer to be conserved. While the composition inside each\n",
    "interaction volume is conserved by construction, we also need to ensure that these\n",
    "volumes do not intersect. If this is not the case we end up with regions of the\n",
    "F-layer where the composition is doubly (and inconsistently) defined. If this is\n",
    "not the case, the total layer composition is constrained by construction and it is\n",
    "easy to evaluate the average liquid composition by noting its volume is just the\n",
    "volume of the layer with the volume of solid particles removed, and that all the \n",
    "oxygen is in the liquid. The problem with this line of attack is that the growth\n",
    "rate of the falling particles, and thus their spacing, depends on the size of the\n",
    "interaction region. Furthermore, if the interaction volumes don't fill space we\n",
    "will have regions of the layer between interaction volumes with reduced oxygen\n",
    "content compared to the interaction volumes. It thus seems that our interaction\n",
    "volumes should fill space and we end up with no flux boundary conditions halfway\n",
    "between each growing particle. In order to set this up we need to self consistently\n",
    "solve the falling particles ODEs using the following algorithem:\n",
    "\n",
    "1. Set an initial guess for the interaction volume radius\n",
    "2. Solve ODEs \n",
    "3. Calculate spacing between particles\n",
    "4. If spacing does not equal radius update radius and repeat from 2 otherwise\n",
    "5. Evaluate mean oxygen content of liquid, crystal size distribution and inner core growth rate.\n",
    "\n",
    "Note that for many falling particles nucleating throughout the layer the volume\n",
    "radius will need to change through the layer (we may expect it will decrease as the\n",
    "number density of particles increases downwards). We thus need to set the interaction\n",
    "volume radius as a parameterised function (analogously to the temperature).\n",
    "\n",
    "Given the above, we need a way to evaluate the number density of particles at any\n",
    "depth in the F-layer. The information we have is the nucleation rate, $\\mathscr{N}(r_n)$, \n",
    "and relationship between the particle position $r_p(r_n, t)$ with time, $t$. Both are functions\n",
    "of the nucleation position $r_n$. We also have access to the particle radius, $R(r_n, t)$. \n",
    "\n",
    "We start by calculating the 'partial number density', number of particles per cubic meter \n",
    "at position $r$ that nucleated at $r_n$. For this we need the spacing between particles nucleating\n",
    "in a given volume around $r_n$, which we call $V_n$. From the definition of $\\mathscr{N}$ we\n",
    "know that the mean waiting time between nucleation events is:\n",
    "\n",
    "$$\\tau = \\frac{1}{2 \\mathscr{N}(r_n) V_n}$$\n",
    "\n",
    "and the mean position of nucleation will be at the center of the volume represented by $V_n$.\n",
    "The factor of a $\\frac{1}{2}$ arised because half of the nuclii that reach the critical radius\n",
    "then dissolve (some definitions of $\\mathscr{N}$ will not include this). $\\tau$ should be in\n",
    "units of time.\n",
    "\n",
    "<b> CD - it looks to me that $\\tau$ is a function of $r_n$ alone: $\\tau = \\tau(r_n)$. I am not quite sure about $V_n$ - is this the interaction volume at the initial location of the particle, i.e. centred at $r_n$. In this case I believe $V_n = V_n(r_n)$. If these two points are true then I think $\\tau$ is the ``mean waiting time between nucleation events at $r_n$''. </b>\n",
    "\n",
    "Particles falling from any given location will follow identicle trajectories whatever time they start (because we are assuming the F-layer is in steady state. <b> CD - Is this not simply true because the particles are assumed to fall vertically down>? Perhaps ``trajectory'' is the wrong word. </b>). That is, if $r_p(r_n, t)$ and $R(r_n, t)$ are solutions to the IVP for a particle nucleating at $t_0$, solutions for an IVP where the particle nucleated at $t_0 + \\tau$ will be $r_p(r_n, t + \\tau)$ and $R(r_n, t + \\tau)$ and we have solutions available whatever the nucleation time. <b> CD - Are you saying here that the 2 particles will always be separated by the same distance as they fall? i.e. because they have the same velocity at all depths the distance travelled for particles 1 and 2 is $d_1 = Vt$ and $d_2 = V(t+\\tau) = Vt + V\\tau = d_1 + V\\tau$ such that $\\Delta d = d_1 - d_2 = V\\tau = constant$ </b>. At some $r$ we can thus calculate the vertical distance, $s_z$ between particles by taking the difference in $r_p$ for particles nucleating $\\tau$ before and after $t_0$:\n",
    "\n",
    "$$s_z = \\frac{\\left(r_p(r_n, t) - r_p(r_n, t + \\tau)\\right) + \\left(r_p(r_n, t - \\tau) + r_p(r_n, t)\\right)}{2}$$\n",
    "\n",
    "<b> CD - I think $s_z = s_z(r_n, t)$, but given the comment above perhaps $s_z = s_z(r_n)$. It is also a function of $\\tau$, which is a function of $r_n$, so this is a shorthand. Also, I believe this is an average of the spacing between particles and $t_0$ and $t_0 + \\tau$ and $t_0$ and $t_0 - \\tau$. This seems reasonable. Hence $s_z$ is the \"average vertical spacing (at time $t$?) between particles that nucleated at time $\\tau$ before and after $t_0$\". \n",
    "\n",
    "I guess this is only true is the nucleation rate is always the same at $r_n$. Perhaps this is the assumption we start with, but in general N could fluctuate due to local changes in P, T, c, etc and also by the statistical nature of the process. Does this make the whole process intractable or just slightly complicate the integrals below? Maybe we discuss discuss the point in the paper. </b>\n",
    "\n",
    "And the vertical partial particle density is $\\rho_p(r_n) = \\frac{1}{s_z}$. The separation between particles in\n",
    "the horizontal direction is determined by the cross sectional area of the nucleation volume \n",
    "(the particles just sink downwards). On average this will be the distance between the centers of\n",
    "the nucleation volumes. If we arrange for the cross-sectional area to be 1 m$^2$ the vertical \n",
    "parital particle density will be the partial particle density (in particles per m$^3$). We can\n",
    "either envisage these particles to nucleate and fall in 'sheets' or imagine a stocastic process\n",
    "(in which case the positions are the mean positions and the density is a mean density. This\n",
    "analysis ignores the change in shell area with radius.\n",
    "\n",
    "<b> CD - Need to discuss this further. The \"sheet\" model is easiest, and presumably requires the number of particles to fit with $4\\pi/3 [(r+dr)^3 - (r-dr)^3]$ where $dr$ relates to the discretisation, e.g. half the separation between radial levels. Not really sure how the \"stochastic\" model works. $r_n$ presumably does not vary laterally because it is just a discretisation. Perhaps we draw nucleation rates from a distribution at a given radius? We are presumably expecting $N$ to depend on $T$, $P$ and $c$ which surely vary radially by much more than they do laterally? </b>\n",
    "\n",
    "We now need to consider the particles that nucleate at other depths. These will have different solutions\n",
    "to the IVP, and thus different seperations and densities. The total (number) density of particles\n",
    "at some depth $\\rho(r)$, is just the sum of the partial densities from all nucleation depths above the height of\n",
    "interest. We can evaluate this as an integral over nucleation depths:\n",
    "\n",
    "$$\\rho(r) = \\int_{r}^{r_{top}} \\rho_p(r_n) \\mathrm{d}r_n $$\n",
    "\n",
    "where $r_{top}$ is the top of the F-layer.\n",
    "\n",
    "<b> CD - I did an example calculation considering two pairs of particles centred around radius $r$ and separated by different distances. In this case I see you are correct that the local particle density around $r$ is the sum of the densities from the individual pairs. So what I think I have verified is that, locally about $r$, \n",
    "\n",
    "$$ \\rho(r) = \\int_{r}^{r_{top}} \\rho_p(r, r_n) \\mathrm{d}r_n $$ .\n",
    "    \n",
    "However, if the comment above is correct (that separation depends only on $r_n$ and not on $r$) then I recover your equation. \n",
    "</b>\n",
    "\n",
    "So we need to calculate $\\rho(r)$ at some set of radii, convert this into a particle seperation, express the \n",
    "seperation as a contiuous function, and feed this back in as the radius of the interaction volume in the IVPs.\n",
    "The iteraction radius (particle seperation) is given by the Wignerâ€“Seitz radius:\n",
    "\n",
    "$$r_{sep}(r) = \\left(\\frac{3}{4\\pi\\rho(r)}\\right)^{\\frac{1}{3}} $$\n",
    "\n",
    "### Inner core growth\n",
    "\n",
    "Once we have a self-consistent solution, it is quite easy to evaluate the solid\n",
    "volume fraction at any radius, and the inner core growth rate. \n",
    "\n",
    "The inner core growth rate (by sedimentation), $G_{ic}$, is given by the volume of solid reaching the\n",
    "ICB per unit time. This is found by integrating the volume of particles that formed everywhere in the \n",
    "F-layer according to their nucleation radius and dividing by the area of the ICB:\n",
    "\n",
    "$$G_{ic} = \\frac{1}{ 4 \\pi r_{icb}^2}\\int_{r_{icb}}^{r_{top}} 4 \\pi r_n^2 . \\frac{4}{3}\\pi R(r_n, t_{icb})^3 . \\frac{\\mathscr{N}(r_n)}{2} \\mathrm{d}r_n $$\n",
    "\n",
    "The term outside the integral is the area of the ICB. The first term inside the intergral accounts for the \n",
    "spherical shell geometry, the second is the volume of the particles as they reach the ICB having nucleated\n",
    "at $r_n$, and the third term gives the number of these particles. The integral is over nucleation position.\n",
    "\n",
    "**To do:** do we actually implement the factor of a half in the nucleation rate?\n",
    "\n",
    "<b> CD - Why does the factor 2 enter here? It appears in $\\tau$ because on average half the particles grow, but here you ust want the nucleation rate. Don't you? </b>\n",
    "\n",
    "\n",
    "### Solid volume fraction\n",
    "\n",
    "The volume fraction solid, $Vf(r)$ at any radius can be evaluated in a similar way as the total volume of solid\n",
    "(per unit volume) is the product of the particle number density and the radii:\n",
    "\n",
    "$$Vf(r) = \\int_{r}^{r_{top}} \\rho_p(r_n) \\frac{4}{3}\\pi R(r_n, t_r)^3 \\mathrm{d}r_n $$\n",
    "\n",
    "**To do:** do we need a geometrical term?\n",
    "\n",
    "<b> CD - what is $V$? volume of solid divided by total volume? So $\\rho$ is number of particles per cubic metre (?) and the other piece is the particle volumes. Reads to me like you get total solid volume per m3. </b>\n",
    "\n",
    "Once we know $Vf(r)$ we can evaluate the liquid composition (and thus density) by conservation of oxygen \n",
    "(all the oxygen is in the liquid).\n",
    "\n",
    "### Implementation\n",
    "\n",
    "We choose a set of integration depths / nucleation depths ($r_n$) above and use each one as the starting\n",
    "depth for the IVP solver and for the descrete depths for numerical integration of the integrals above. \n",
    "Some brief testing seems to show that O(10) is more than enough points for the case I looked at (but careful\n",
    "checking may be useful). We also choose a set of radii (just $r$ above) where we want to evaluate $\\rho_p$ and \n",
    "$Vf$. We provide these to the IVP solver as non terminal 'events' and also check for dissolution of the particle\n",
    "and for the particle hitting the ICB (these are 'terminal events'). What this means is that we can easily get hold\n",
    "of the time and particle radius when the solution hit these depths from the IVP solution objects. We run each IVP\n",
    "and store the solution objects in a list. We also need to apply small changes to the time to work out the \n",
    "seperation between particles. We do this by asking the IVP solver to fit an interpolation function to the solution.\n",
    "We can then use the time (from the event) and apply an offset to find the position the particle was at a short time\n",
    "before or after the event was triggered. We can use the termination event to find the ICB growth rate. To make this\n",
    "all work we need to know when event corresponds to which depth. Events are stored (in the IVP solution) in a list.\n",
    "Event 0 is 'hit the ICB', event 1 is 'dissolved' and subsiquent events correspond to our analysis radii in order.\n",
    "Note that accessing these events needs us to check that the particle has not dissovled (or never reached) the analysis\n",
    "radius of interest. Super. Glad that makes sense. It is also useful to know that the events information is stored in\n",
    "`t_events` (for times) and `y_events` (for radius, in element 0, and position, in element 1). \n",
    "\n",
    "This may all make a bit more sense in terms of code. The function in the next cell just dumps out everything we \n",
    "know about the events found in a single IVP solution. Last thing to watch - events can (in principle) be triggered\n",
    "multiple times, so we have to watch for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_all_solution_events(sol, analysis_depths):\n",
    "    \"\"\"\n",
    "    Print out what happend to a single ODE IVP falling calculation\n",
    "    \n",
    "    We are careful to check when things don't happen. And check for \n",
    "    double crossings of depths (say we have upward falling) but just\n",
    "    treat that as an error for now.\n",
    "    \"\"\"\n",
    "    if not sol.t_events[0].size > 0:\n",
    "        print('did not reach icb')\n",
    "    else:\n",
    "        assert sol.t_events[0].size == 1, \"Double crossing detected\"\n",
    "        print('icb at t = ', sol.t_events[0][0], 's, with particle radius = ', sol.y_events[0][0][0])\n",
    "    \n",
    "    if not sol.t_events[1].size > 0:\n",
    "        print('did not dissolve')\n",
    "    else:\n",
    "        print('particle dissolved at t = ', sol.t_events[1][0], 's')\n",
    "    for i, r in enumerate(analysis_depths):\n",
    "        if sol.t_events[i+2].size > 0:\n",
    "            assert sol.t_events[i+2].size == 1, \"Double crossing detected\"\n",
    "            print(\"reached r = \", r, 'm at t = ', sol.t_events[i+2][0], 's, with particle radius = ', sol.y_events[i+2][0][0])\n",
    "        else:\n",
    "            print('did not reach r = ', r, 'm')\n",
    "    print(\"\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc741bfc",
   "metadata": {},
   "source": [
    "The following cell contains all the code to actually do the \n",
    "self consistent soluton. Needs clean up. In particular\n",
    "\n",
    "**To do:** \n",
    "\n",
    "1. don't access the F-layer setup functions from the global scope,\n",
    "pass them as arguments (global state is bad\n",
    "2. consider making `run_ivps_for_snow_zone` run the IVPs in parallel\n",
    "3. reduce prited output (pass in and use a verbose argument everywhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate parile seperation and 'partial' density\n",
    "def partial_particle_density(ivp_solution, event_index, nucleation_rate, nucleation_volume, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate the 'partial' particle density at a given radius given a single solution to the IVP\n",
    "    \n",
    "\n",
    "    ivp_solution: solution object for IVP. Must have events attached. Must also have dense \n",
    "            output (i.e. a smooth interpolator) attached\n",
    "    event_index: index into list of events in ivp_solution where analysis is to be perfomed. \n",
    "            This must correspond to the particle crossing the depth of interest and a sutible\n",
    "            'event' must thus be attached to the IVP solution object. The event need not have\n",
    "            been triggered (e.g. the particles could dissolve before reaching the radius of\n",
    "            interest). \n",
    "    nucleation_rate: the rate of nucleation for the radius corresponding to t=0 for the IVP\n",
    "            This is where the particles we are forming before they fall through our radius\n",
    "            of interest (in particles per m^3 per s).\n",
    "    nucleation_volume: the volume where nucleation takes place (in m^3)\n",
    "    \n",
    "    Returns the partial particle density in particles per m^3 nucleating in the volume\n",
    "    represented by the start of the IVP. This must be integrated to find the total density.\n",
    "    (See notes in the notebook re. statistical meaning of this given CNT!)\n",
    "    \"\"\"\n",
    "    # Calculate the average time between nucleation events, this is the 'waiting time'\n",
    "    # of Davies et al. 2019 and includes a factor of 1/2 to account for half of the \n",
    "    # particles reaching r_c then dissolving.\n",
    "    tau = 1.0/(2.0*nucleation_rate*nucleation_volume)\n",
    "    \n",
    "    # Find the time where a particle that nucleated at t=0 reached the radius of interest\n",
    "    # by searching through the IVP events. This cannot be the first (hit ICB) or second\n",
    "    # (dissolved) event. We need to check even if it did dissolve as that could be below the\n",
    "    # radius of interest.\n",
    "    assert event_index > 1, \"Cannot processes hit ICB or dissolved data\"\n",
    "    if ivp_solution.t_events[event_index].size > 0:\n",
    "        assert ivp_solution.t_events[event_index].size == 1, \"Double crossing detected\"\n",
    "        # NB: solution y_events indexed by event, then a list of times where the event is\n",
    "        # seen (we want the first one - index 0) then a list of ys (i.e. particle radius, position)\n",
    "        # and want the position which is index 1 \n",
    "        analysis_radius = ivp_solution.y_events[event_index][0][1]\n",
    "        analysis_time = ivp_solution.t_events[event_index][0]\n",
    "        # We'll take the distances between this particle (nucleated at t=0) and the\n",
    "        # one before (nucleated at t = -tau) and the one after (t = tau). Because we \n",
    "        # have a steady state solution the whole IVP solution is just shifted in time\n",
    "        # so we can do the analysis from just this solution and use the dense output\n",
    "        # to get the distance\n",
    "        assert ivp_solution.sol(analysis_time)[1] == analysis_radius, \"event / interpolator missmatch\"\n",
    "        if (analysis_time - tau) < 0.0:\n",
    "            print(\"cannot process if next particle has yet to form\")\n",
    "            return 0.0\n",
    "        if (analysis_time + tau) > ivp_solution.t[-1]:\n",
    "            print(\"cannot process if previous particle has gone\")\n",
    "            return 0.0\n",
    "        distance_below = analysis_radius - ivp_solution.sol(analysis_time + tau)[1]\n",
    "        distance_above = ivp_solution.sol(analysis_time - tau)[1] - analysis_radius\n",
    "        partial_density = 1.0 / (0.5 * (distance_below + distance_above)) # /m^3 - see notebook!\n",
    "        if verbose:\n",
    "            print(\"Partial density calculation at r = \", analysis_radius, \"m\")\n",
    "            print(\"At time t = \", analysis_time, \"s, and tau = \", tau, \"s\")\n",
    "            print(\"Previous particle is\", distance_below, \"m below, next particle is\", distance_above, \"m above\")\n",
    "            print(\"Partial particle densituy is\", partial_density, \"particles / m^3\")     \n",
    "    else:\n",
    "        # No particles at this depth (above nucleation depth or dissolved)\n",
    "        # partial density is zero\n",
    "        partial_density = 0.0\n",
    "        if verbose:\n",
    "            print(\"No event data (e.g. dissolved) so partical density is zero\")\n",
    "        \n",
    "    return partial_density\n",
    "\n",
    "\n",
    "# Actually run the IVPs\n",
    "def run_ivps_for_snow_zone(analysis_depths, integration_depths, nucleation_rates, seperations):\n",
    "    # FIXME: other parameters should be arguments\n",
    "    solutions = []\n",
    "    for int_depth in integration_depths:\n",
    "        print(\"Starting ODE IVP solver for nuclation at\", int_depth)\n",
    "        sol = boundary_layer.falling_growing_particle_solution(start_time, max_time, initial_particle_size, \n",
    "                                                       int_depth, xfunc, seperations, tfunc, pfunc,\n",
    "                                                       dl, k0, gfunc, mu, radius_inner_core, analysis_depths)\n",
    "        assert sol.success, \"No ODE solution found!\"\n",
    "        report_all_solution_events(sol, analysis_depths)\n",
    "        solutions.append(sol)\n",
    "        \n",
    "    return solutions\n",
    "\n",
    "\n",
    "# Total particle density and solid volume fraction calculation\n",
    "def evaluate_partcle_densities(solutions, analysis_depths, integration_depths, nucleation_rates, max_sep=1000.0):\n",
    "    # FIXME: other parameters should be arguments\n",
    "\n",
    "    print(\"ODE solved for all nuclation depths... calculating integrals over nuclation depth for particle density\")\n",
    "    particle_densities = np.zeros_like(analysis_depths)\n",
    "    solid_vf = np.zeros_like(analysis_depths)\n",
    "    particle_radius_histogram = np.zeros((analysis_depths.size, integration_depths.size))\n",
    "    particle_radius_unnormalised = np.zeros((analysis_depths.size, integration_depths.size))\n",
    "    for i, analysis_r in enumerate(analysis_depths):\n",
    "        analysis_index = i + 2\n",
    "        # Particle density at this depth is 'just' the partial density\n",
    "        # (density from nucleation depth) integrated over nuclation depths\n",
    "        # It's okay to integrate nuc depths below int depth as this will\n",
    "        # return zero density. This is a 1D integral (see notebook)\n",
    "        partial_densities = np.zeros_like(integration_depths)\n",
    "        partial_radius = np.zeros_like(integration_depths)\n",
    "        for j, int_r in enumerate(integration_depths):\n",
    "            # Skip if this will be zero - avoid noise\n",
    "            if analysis_r > int_r:\n",
    "                partial_densities[j] = 0.0\n",
    "                next\n",
    "                \n",
    "            nuc_rate = nucleation_rates[j]\n",
    "            nuc_area = 1000.0*1000.0\n",
    "            if j == 0:\n",
    "                # Innermost layer\n",
    "                nuc_vol = nuc_area * (integration_depths[0] + 0.5 * (\n",
    "                                      integration_depths[1] - integration_depths[0])\n",
    "                                     ) - radius_inner_core \n",
    "            elif (j + 1) == integration_depths.size:\n",
    "                # Outermost layer\n",
    "                nuc_vol = nuc_area * radius_top_flayer - (integration_depths[-2] + 0.5 * (\n",
    "                                      integration_depths[-1] - integration_depths[-2])\n",
    "                                     )\n",
    "            else:\n",
    "                nuc_vol = nuc_area * ((integration_depths[j] + 0.5 * (\n",
    "                                      integration_depths[j+1] - integration_depths[j]))\n",
    "                                  - (integration_depths[j-1] + 0.5 * (\n",
    "                                      integration_depths[j] - integration_depths[j-1])\n",
    "                                    ))\n",
    "            print(\"\\nPartial density calc for i = \", i, \"and j = \", j, \"nuc_rate = \", nuc_rate, \"nuc_vol = \", nuc_vol)\n",
    "            print(\"Analysis r = \", analysis_r, \"int r = \", int_r)\n",
    "            partial_densities[j] = partial_particle_density(solutions[j], analysis_index, \n",
    "                                                            nuc_rate, nuc_vol, verbose=True)\n",
    "            \n",
    "            # Put radius at this radius and nuc radius in radius histogram\n",
    "            if solutions[j].t_events[analysis_index].size > 0:\n",
    "                # Triggered event - no check for double crossing as partial_particle_density will have done this\n",
    "                particle_radius_unnormalised[i,j] = solutions[j].y_events[analysis_index][0][0]\n",
    "                particle_radius_histogram[i,j] = particle_radius_unnormalised[i,j]*partial_densities[j]\n",
    "                partial_radius[j] = particle_radius_unnormalised[i,j]\n",
    "            else:\n",
    "                # Melted etc\n",
    "                particle_radius_unnormalised[i,j] = 0.0\n",
    "                particle_radius_histogram[i,j] = 0.0\n",
    "                partial_radius[j] = 0.0\n",
    "            \n",
    "        # Number density of particles at this radius\n",
    "        particle_density = np.trapz(partial_densities, integration_depths) / nuc_area # See units note...\n",
    "        print(\"\\nTotal particle density at r = \", analysis_r, \"is\", particle_density, \"particles per m^3\")\n",
    "        particle_densities[i] = particle_density\n",
    "        \n",
    "        # Solid volume fraction of particles at this radius - this is partial number density multiplied\n",
    "        # by particle volume integrated over nucleation height. While we are here also build a grain size\n",
    "        # distribution histogramme at each radius\n",
    "        solid_vf[i] = np.trapz(4/3*np.pi*partial_radius**3 * (partial_densities / nuc_area), integration_depths)\n",
    "        print(\"Solid volume fraction at r = \", analysis_r, \" is \", solid_vf[i])\n",
    "        \n",
    "    # Evaluate seperation of particles (to allow self consistent solution)\n",
    "    calculated_seperation = np.zeros_like(analysis_depths)\n",
    "    for i, rad in enumerate (analysis_depths):\n",
    "        rho = particle_densities[i]\n",
    "        if rho > 0.0:\n",
    "            sep = (3.0/(4.0*np.pi*rho))**(1.0/3.0)\n",
    "            if sep > max_sep:\n",
    "                sep = max_sep\n",
    "        else:\n",
    "            # Assign nominal seperation based on min density\n",
    "            sep = max_sep\n",
    "        calculated_seperation[i] = sep\n",
    "        print(\"Ar r =\", rad, \"m, particle density = \", rho, 'per m^3, calculated seperation radius = ', sep, 'm')\n",
    "       \n",
    "    return particle_densities, calculated_seperation, solid_vf, particle_radius_unnormalised, particle_radius_histogram\n",
    "\n",
    "\n",
    "# Just calculate the core growth rate.\n",
    "def evaluate_core_growth_rate(solutions, integration_depths, nucleation_rates):\n",
    "    # FIXME: other parameters should be arguments\n",
    "    print(\"\\nODE solved for all nuclation depths... calculating integrals over nuclation depth for inner core growth\")\n",
    "    \n",
    "    # IC growth rate should be okay\n",
    "    # We build up an array of solid volume as a function\n",
    "    # of nuc depth and integrate\n",
    "    particle_volumes = np.zeros_like(nucleation_rates)\n",
    "    for i, sol in enumerate(solutions):\n",
    "        if not sol.t_events[0].size > 0:\n",
    "            # Disolved before reaching ICB\n",
    "            p_radius = 0.0\n",
    "            particle_volumes[i] = 0.0\n",
    "        elif sol.t_events[0].size == 1:\n",
    "            # Particle reached ICB exactly once\n",
    "            p_radius = sol.y_events[0][0][0]\n",
    "            particle_volumes[i] = 4/3 * np.pi * p_radius**3\n",
    "        else:\n",
    "            # Impossible multiple crossing of ICB\n",
    "            raise NotImplementedError\n",
    "            \n",
    "    area_icb = 4.0 * np.pi * radius_inner_core**2\n",
    "    growth_rate = np.trapz(particle_volumes * nucleation_rates * integration_depths**2 * 4.0 * np.pi, \n",
    "                           integration_depths) / area_icb\n",
    "    \n",
    "    secinMyr = 60.0*60.0*24.0*365.0*1000000.0\n",
    "    print(\"Inner core growth rate:\", growth_rate, \"m/s\")\n",
    "    print(\"Inner core growth rate:\", growth_rate/1000.0 * secinMyr, \"km/Myr (or mm/yr)\")\n",
    "    return growth_rate\n",
    "    \n",
    "    \n",
    "# Run a single set of IVP problems and do the analysis\n",
    "# Fitst create a interpolator for the ineteraction radius.\n",
    "def integrate_snow_zone(analysis_depths, integration_depths, nucleation_rates, imposed_seperations, max_sep=1000.0):\n",
    "    # FIXME: other parameters should be arguments\n",
    "    \n",
    "    # Interpolation function for seperations\n",
    "    sep_function = spi.interp1d(analysis_depths, imposed_seperations, fill_value='extrapolate')\n",
    "    \n",
    "    solutions = run_ivps_for_snow_zone(analysis_depths, integration_depths, nucleation_rates, sep_function)\n",
    "    \n",
    "    particle_densities, calculated_seperation, solid_vf, particle_radius_unnormalised, particle_radius_histogram = evaluate_partcle_densities(solutions, \n",
    "                                        analysis_depths, integration_depths, nucleation_rates, max_sep)\n",
    "    \n",
    "    growth_rate = evaluate_core_growth_rate(solutions, integration_depths, nucleation_rates)\n",
    "    \n",
    "    return solutions, particle_densities, calculated_seperation, growth_rate, solid_vf, particle_radius_unnormalised, particle_radius_histogram\n",
    "    \n",
    "\n",
    "# THis is no longer used - it allows us to use a minimiser to do the self consistent solution.\n",
    "def _seperation_function_missfit(seperations_in, analysis_depths, integration_depths, nucleation_rates, max_sep=1000.0):\n",
    "    \"\"\"\n",
    "    Return the root mean squared misfit betwen input seperations and calculated seperations\n",
    "    \"\"\"\n",
    "    print(\"Calculating RMS error for seperations\", seperations_in)\n",
    "    # Interpolation function for seperations\n",
    "    sep_function = spi.interp1d(analysis_depths, seperations_in, fill_value='extrapolate')\n",
    "    solutions = run_ivps_for_snow_zone(analysis_depths, integration_depths, nucleation_rates, sep_function)\n",
    "    particle_densities, calculated_seperation, _, _, _ = evaluate_partcle_densities(solutions, \n",
    "                                        analysis_depths, integration_depths, nucleation_rates, max_sep)\n",
    "    rms_error = np.sqrt(np.mean((seperations_in - calculated_seperation)**2))\n",
    "    print(\"\\n\\n**** RMS ERROR:\", rms_error, \"****\\n\\n\")\n",
    "    return rms_error\n",
    "    \n",
    "    \n",
    "# This controls the self consistnet solution\n",
    "def solve_flayer(nucleation_radii, nucleation_rates, analysis_radii, initial_interaction_radii=None,\n",
    "                maximum_seperation=3.0, max_rel_error=0.01, max_absolute_error=0.001):\n",
    "    \"\"\"\n",
    "    Create a self consistent solution for the F-layer assuming non-equilibrium growth and falling\n",
    "    of iron crystals\n",
    "    \n",
    "    This involves integration of the results from falling-growing crystal calculations with the\n",
    "    integration being with respect to the nucleation radius. We thus need to perform the calculations\n",
    "    at a set of (provided) nucleation radii for the integration. Each of thse is assoceated with \n",
    "    a nucleation rate. We calculate the density of falling particles (and thus their seperation)\n",
    "    at a number of analysis radii. Part of the calculation needs us to know an interaction region\n",
    "    around each particle. This is found self consistently, but an initial guess can be provided.\n",
    "    \n",
    "    Input arguments:\n",
    "    \n",
    "    nucleation_radii: The radii where we explicity consider nuclation to take place. These are used\n",
    "        as integration points for a numerical integration over the whole nucleating layer so we need\n",
    "        enough of thse to converge. However, as the solution seems to be well behaved O(10) seems to\n",
    "        be enough. A 1D array of radii (measured outwards from the center of the Earth) in m.\n",
    "    nucleation_rates: The nucleation rate (in events per m^3 per s) at each nucleation_radii. 1D array\n",
    "    analysis_radii: locations where the particle density and other output parameters are calculated.\n",
    "        1D array in m. No particular relationship with nucleation radii assumes. This is also the place\n",
    "        where the self conssitency of the solution is checked.\n",
    "    initial_interaction_radii: an initial guess at the interaction radius at each analysis_radii. Interpolatied\n",
    "        for all other radii (using linear interpolator). Defaults to 1m.\n",
    "    maximum_seperation: how big can we let the seperation get. Defaults to 3m.\n",
    "    max_rel_error: maximum relative error on any particle radius at any analysis position to be considered converged. \n",
    "        Defaults to 1%\n",
    "    max_rel_error: maximum absolute error on any particle radius at any analysis position to be considered converged. \n",
    "        Defaults to 1 mm.\n",
    "        \n",
    "    Returns:\n",
    "    solutions: list of IVP solution objects, one per nucleation_radii\n",
    "    particle_densities: array of total particle number densities (particles per m^3) evaluated at the\n",
    "        analysis_radii\n",
    "    calculated_interaction_radii: mean seperation between particles, evaluated at the analysis_radii (in m)\n",
    "    icb_growth_rate: calculated growth rate of the inner core (in m/s)\n",
    "    solid_vf: volume fraction solid evaluated at each analysis_radii\n",
    "    particle_radius_unnormalised: 2D numpy array of size (analysis_radii, nucleation_radii) giving \n",
    "        giving the crystal radius measured at an analysis radius which nucleated at a nucleation radius.\n",
    "    particle_radius_histogram: 2D numpy array of size (analysis_radii, nucleation_radii) giving the\n",
    "        product of the particle radius and corresponding density at each analysis radius for each nucleation\n",
    "        radius.\n",
    "    \"\"\"\n",
    "    if initial_interaction_radii is None:\n",
    "        initial_interaction_radii = np.ones_like(analysis_radii)\n",
    "    \n",
    "    # Calculate an initial guess using the provided seperations\n",
    "    solutions, particle_densities, calculated_interaction_radii, growth_rate, solid_vf, \\\n",
    "        particle_radius_unnormalised, particle_radius_histogram = integrate_snow_zone(\n",
    "        analysis_radii, nucleation_radii, nucleation_rates, initial_interaction_radii, \n",
    "        maximum_seperation)\n",
    "    \n",
    "    converged = False\n",
    "    while not converged:\n",
    "        # Recalculate solution with updated seperations\n",
    "        solutions, particle_densities, calculated_interaction_radii, growth_rate, solid_vf, \\\n",
    "             new_particle_radius_unnormalised, particle_radius_histogram = integrate_snow_zone(\n",
    "             analysis_radii, nucleation_radii, nucleation_rates, calculated_interaction_radii, \n",
    "             maximum_seperation)\n",
    "        converged = np.allclose(particle_radius_unnormalised, new_particle_radius_unnormalised,\n",
    "                                atol=max_absolute_error, rtol=max_rel_error)\n",
    "        particle_radius_unnormalised = new_particle_radius_unnormalised\n",
    "        \n",
    "    return solutions, particle_densities, calculated_interaction_radii, growth_rate, solid_vf, \\\n",
    "        particle_radius_unnormalised, particle_radius_histogram   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca25a9",
   "metadata": {},
   "source": [
    "### The actual integration\n",
    "\n",
    "The next couple of cells shows how this can be used and illustrate one solution. \n",
    "\n",
    "Note that as well as F-layer setup (above) we have other parameters to set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVP defaults\n",
    "start_time = 0 # s\n",
    "max_time = 100000000000 # s\n",
    "rtot = 1.0 # initial interaction radius\n",
    "\n",
    "# Physical properties\n",
    "initial_particle_size = 1.0E-10 # initial radius, m - should be critical radius for nucleation\n",
    "k0 = 150.0 # growth rate prefactor, m/s\n",
    "dl = 1.0E-9 # diffusion\n",
    "mu = 1.0e-6 # kinematic viscosity\n",
    "\n",
    "nucleation_radii = np.linspace(radius_inner_core+1000.0, radius_top_flayer-1000.0, 10)\n",
    "analysis_radii = np.linspace(radius_inner_core+500.0, radius_top_flayer-1500.0, 5)\n",
    "initial_seperations = np.ones_like(analysis_radii)*rtot\n",
    "nucleation_rates = np.ones_like(nucleation_radii)*1.0E-14 # Same everywhere\n",
    "maximum_seperation = 3.0 # Don't let this be too big - root finder in oxygen conservation in \n",
    "                         # region of interest not accurate enough.\n",
    "\n",
    "solutions, particle_densities, calculated_interaction_radii, growth_rate, solid_vf, \\\n",
    "    particle_radius_unnormalised, particle_radius_histogram = solve_flayer(\n",
    "    nucleation_radii, nucleation_rates, analysis_radii, initial_seperations, \n",
    "    maximum_seperation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ec04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(analysis_radii/1000.0, solid_vf*1.0E6, label='Non-equilibrium * 1E6')\n",
    "ax.plot(rs/1000.0, feot.volume_fraction_solid(xs, ps, ts), label='equilibriun')\n",
    "ax.set_ylabel('Volume fraction solid')\n",
    "ax.set_xlabel('Radius (km)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(analysis_radii/1000.0, np.max(particle_radius_unnormalised, axis=1))\n",
    "ax.set_xlabel('Radius (km)')\n",
    "ax.set_ylabel('Maximum crystal radius (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a27e9",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "What next? It seems we can proceed in three ways:\n",
    "\n",
    "1. Find $\\frac{\\mathscr{N}}{\\mathscr{F}}$ that gives 1 km/Myr (or whatever) for G. Evaluate the resulting seismic structure of the F-layer.\n",
    "2. Use $\\mathscr{N}$ (from previous work, and this can then depend on $z$). Assume $\\mathscr{F}$ is 1 (or whatever) and compare with F-layer\n",
    "3. Do a comparison between equilibrium and non-equilibrium case (as close as we can manage).\n",
    "\n",
    "However, first we may want to think about remove the interaction radius thing all togher. Instead we can\n",
    "just use the 'F-layer liquid composition' as the composition on the outside edge of the bounday layer,\n",
    "let this be radius dependent, and update this in the self consistent loop. This ought to be fine \n",
    "but I'm not sure how we can illustrate a single particle case if we do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aafb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
